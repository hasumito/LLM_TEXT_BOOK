## 5.2. Multi-Head Attention：表現の分解と再結合

Self-Attention（5.1節）は、Query/Key/Value（Q/K/V）に基づき、系列中の各トークンが他トークンを参照して情報を混合する機構である。しかし、単一の注意（single-head）だけでは「どの観点で関係を見るか」を1種類の類似度に押し込めることになりやすい。自然言語では、同じ文脈でも係り受け・照応・語彙的類似・談話構造など、同時に複数の関係が重なって成立する。Multi-Head Attention（多頭注意）は、この「関係の多面性」をモデルの内部表現として扱うために、表現空間を複数の部分空間へ分解し、それぞれで独立に注意を計算してから再結合する設計である。

### 多頭化の定義：複数の射影と独立な注意

入力（各位置の隠れ状態）を行列 (X \in \mathbb{R}^{n \times d_{\text{model}}}) とする。Multi-Head Attentionでは、ヘッド数を (h) とし、各ヘッド (i) ごとに異なる線形射影を用いて
[
Q_i = X W_i^Q,\quad K_i = X W_i^K,\quad V_i = X W_i^V
]
を作る。ここで
[
W_i^Q \in \mathbb{R}^{d_{\text{model}}\times d_k},\
W_i^K \in \mathbb{R}^{d_{\text{model}}\times d_k},\
W_i^V \in \mathbb{R}^{d_{\text{model}}\times d_v}
]
である。各ヘッドは、射影後の空間で scaled dot-product attention を独立に実行する：
[
\text{head}_i = \text{Attention}(Q_i, K_i, V_i)
= \text{softmax}!\left(\frac{Q_i K_i^\top}{\sqrt{d_k}} + M\right)V_i
]
ここで (M) は必要に応じてマスク（デコーダLMでは因果マスク）であり、将来位置への参照を禁止するために加算される。

最後に全ヘッドの出力を特徴次元で結合（concatenate）し、もう一度線形変換して元の次元へ戻す：
[
\text{MultiHead}(X) = \text{Concat}(\text{head}*1,\dots,\text{head}*h), W^O
]
[
W^O \in \mathbb{R}^{(h d_v)\times d*{\text{model}}}
]
典型的には (d_k=d_v=d*{\text{model}}/h) とし、計算量を単頭と同程度に保ちつつ、表現の「観点」を増やす。

### 直観：表現の分解（subspace）と再結合（mixture）

多頭注意の要点は、注意の計算そのものよりも「Q/K/Vをヘッドごとに別の線形部分空間へ投影する」点にある。各ヘッドは同じ入力 (X) を見ているが、異なる射影行列により「見るための座標系」が異なる。結果として、あるヘッドは近接語の局所依存を強く拾い、別のヘッドは遠距離の照応や句構造に敏感になる、といった分業が起こり得る。再結合の段階（(W^O)）では、これら複数の観点で得られた情報を、次の層が使いやすい形へ混ぜ直す。すなわち Multi-Head Attention は、**関係の抽出器を並列化し、その出力を統合する**構造である。

この分解と再結合は、単に「同じ注意をh回やる」こととは異なる。単頭注意を単純に幅広くするだけでは、単一の類似度行列に多様な関係を同居させる必要がある。一方、多頭化では、ヘッドごとに異なる類似度行列（(Q_iK_i^\top)）を持てるため、関係の表現が干渉しにくい。

### なぜ効くのか：表現力・最適化・情報のボトルネック

多頭注意が有効である理由は、少なくとも三つの観点で理解できる。

1. **表現力の増加（多様な関係の同時表現）**
   注意は「重み付き平均」であり、単一の重み付けでは表現できる混合の種類が限られる。多頭化は、異なる重み付けを並列に持つことで、同一トークン表現に対して複数のコンテキスト要約を同時に作れる。これは言語の多義性・多関係性に対して自然な帰納バイアス（学習が向かいやすい制約）を与える。

2. **最適化の容易さ（探索空間の分割）**
   巨大な (d_{\text{model}}) 空間で単頭の射影を学ぶより、複数の小さな (d_k) 空間に分けて学ぶ方が、学習が安定しやすい場合がある。各ヘッドが「局所的な役割」を獲得しやすく、勾配が分散することで特定の注意パターンへの過度な集中が緩和されることがある（ただし一般則ではなく、設計・データ・正則化に依存する）。

3. **情報ボトルネックの制御（並列な経路）**
   Self-Attention層は、位置間で情報をやり取りする主要な経路である。多頭化は経路を複線化し、ある種の情報（例：構文）と別種の情報（例：語彙類似）を同時に運べる。これは後段のFFNや残差接続と組み合わさり、層ごとの役割分担を促す。

### 誤解しやすい点：ヘッドは「解釈可能な部品」ではない

多頭注意はしばしば「ヘッドごとに意味がある」と説明されるが、ヘッドの役割は必ずしも一意でも安定でもない。学習の結果として、ヘッド間で冗長性が生まれることがあり、いくつかのヘッドを剪定（pruning）しても性能低下が小さい場合がある。また、注意重みが高いことは「因果的に重要」を意味しない（注意＝説明、とは限らない）。したがって、ヘッドを人間の概念に安易に対応づけるのは危険であり、解釈は仮説として扱うべきである。

### 別の見方：Multi-Headは「低ランクな関係行列のアンサンブル」

注意の中心量である類似度行列 (QK^\top) は、射影によって構造が制約される。多頭化は、異なる射影で得られる複数の類似度行列を並列に持ち、出力側で統合する。これは「単一の巨大な関係行列」を学ぶ代わりに、「複数の部分的な関係行列のアンサンブル」を学ぶ見方に近い。この見方は、多頭化が表現の多様性と学習の頑健性を得やすいことを説明する。

以上より、Multi-Head Attentionは、自己注意を単に強化する技巧ではなく、**表現を複数の観点に分解し、独立に関係を抽出してから再結合する**という、Transformerの中心的な設計原理である。多頭化は言語に内在する多関係性に対して適切な帰納バイアスを与え、以降の層（位置情報・残差・FFN）と組み合わさることで、深い表現学習を可能にする。

